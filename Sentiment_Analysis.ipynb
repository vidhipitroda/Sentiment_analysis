{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNAVu6JdgLWDwSATL7mwRL+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vidhipitroda/Sentiment_analysis/blob/master/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM8Y0WRNvwzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f54aa12b-a2c3-41a5-9546-6d49f0790016"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXYASOsywBpx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "17f0c6cc-1b6e-47c7-8695-542c09aef836"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "example_sent = \"this is a sample sentence, showing off the stop words filtration\"\n",
        "example_sent = example_sent.lower()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "word_tokens = word_tokenize(example_sent)\n",
        "print(word_tokens)\n",
        "#clean the words\n",
        "punctuations = \"?:!.,;\"\n",
        "for w in word_tokens:\n",
        "  if w in punctuations:\n",
        "    word_tokens.remove(w)\n",
        "    print(word_tokens)\n",
        "filtered_sentence=[w for w in word_tokens if not w in stop_words]\n",
        "print(filtered_sentence)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['this', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration']\n",
            "['this', 'is', 'a', 'sample', 'sentence', 'showing', 'off', 'the', 'stop', 'words', 'filtration']\n",
            "['sample', 'sentence', 'showing', 'stop', 'words', 'filtration']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FaJ2O9vxEJ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "53be273e-dc72-4283-d9b9-b908d29fe023"
      },
      "source": [
        "#stemming and lemmatization\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer\n",
        "porter = PorterStemmer()\n",
        "lancaster=LancasterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "stemSent_Porter = []\n",
        "stemSent_Lancaster = []\n",
        "lemmaSent = []\n",
        "for w in filtered_sentence:\n",
        "  stemSent_Porter.append(porter.stem(w))\n",
        "  stemSent_Lancaster.append(lancaster.stem(w))\n",
        "  lemmaSent.append(wordnet_lemmatizer.lemmatize(w))\n",
        "  print(stemSent_Porter)\n",
        "  print(stemSent_Lancaster)\n",
        "  print(lemmaSent)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sampl']\n",
            "['sampl']\n",
            "['sample']\n",
            "['sampl', 'sentenc']\n",
            "['sampl', 'sent']\n",
            "['sample', 'sentence']\n",
            "['sampl', 'sentenc', 'show']\n",
            "['sampl', 'sent', 'show']\n",
            "['sample', 'sentence', 'showing']\n",
            "['sampl', 'sentenc', 'show', 'stop']\n",
            "['sampl', 'sent', 'show', 'stop']\n",
            "['sample', 'sentence', 'showing', 'stop']\n",
            "['sampl', 'sentenc', 'show', 'stop', 'word']\n",
            "['sampl', 'sent', 'show', 'stop', 'word']\n",
            "['sample', 'sentence', 'showing', 'stop', 'word']\n",
            "['sampl', 'sentenc', 'show', 'stop', 'word', 'filtrat']\n",
            "['sampl', 'sent', 'show', 'stop', 'word', 'filt']\n",
            "['sample', 'sentence', 'showing', 'stop', 'word', 'filtration']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM6jg5Ssy3Fi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "235f787b-af41-496f-c639-3c590eff0ec1"
      },
      "source": [
        "import nltk\n",
        "nltk.download('tagsets')\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4om9NSIZzOKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3cf2717d-b694-40d7-8407-704153752759"
      },
      "source": [
        "text = word_tokenize(\"And now for something completely different\")\n",
        "nltk.pos_tag(text)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('And', 'CC'),\n",
              " ('now', 'RB'),\n",
              " ('for', 'IN'),\n",
              " ('something', 'NN'),\n",
              " ('completely', 'RB'),\n",
              " ('different', 'JJ')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYjhD2QazYj5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7fd07582-d70a-4d1b-f085-020695c36148"
      },
      "source": [
        "nltk.help.upenn_tagset('CC')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CC: conjunction, coordinating\n",
            "    & 'n and both but either et for less minus neither nor or plus so\n",
            "    therefore times v. versus vs. whether yet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm09MJ-YzfTq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "237e21ac-1833-4714-f589-76e7c44d2dbf"
      },
      "source": [
        "#Naive bayes classificaiton from scratch\n",
        "import nltk\n",
        "import random\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import movie_reviews\n",
        "documents = []\n",
        "for category in movie_reviews.categories():\n",
        "  for fileid in movie_reviews.fileids(category):\n",
        "    documents.append([list(movie_reviews.words(fileid)),category])\n",
        "random.shuffle(documents)\n",
        "print(documents[1][0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "['call', '\"', 'hush', '\"', '\"', 'stop', 'or', 'my', 'mom', 'will', 'kill', '.', '\"', 'or', '\"', 'mommy', 'fearest', '.', '\"', 'or', '\"', 'the', 'hand', 'that', 'robs', 'the', 'cradle', '.', '\"', 'call', 'it', 'whatever', 'you', 'want', ',', 'but', 'certainly', 'don', \"'\", 't', 'see', 'it', 'unless', 'you', \"'\", 're', 'in', 'desperate', 'need', 'of', 'a', 'bad', 'movie', '-', 'induced', 'chuckle', '--', '\"', 'hush', '\"', 'scores', 'so', 'many', 'unintentional', 'guffaws', 'that', 'it', 'almost', 'qualifies', 'as', 'a', 'guilty', 'pleasure', '.', 'chalk', 'its', 'losses', 'up', 'to', 'frequent', 'stupidity', 'lapses', 'and', 'apparent', 'post', '-', 'production', 'tinkering', '(', 'it', 'was', 'supposed', 'to', 'open', 'about', 'a', 'year', 'ago', ')', ',', 'the', 'latter', 'of', 'which', 'appears', 'to', 'have', 'given', '\"', 'hush', '\"', 'a', 'send', '-', 'off', 'that', \"'\", 's', 'downright', 'infuriating', '.', 'it', \"'\", 's', 'too', 'bad', 'that', '\"', 'hush', '\"', 'is', 'so', 'laughable', ',', 'because', 'the', 'on', '-', 'screen', 'talent', '--', 'including', 'the', 'pairing', 'of', 'gwyneth', 'paltrow', 'and', 'jessica', 'lange', '--', 'is', 'nothing', 'to', 'laugh', 'at', '.', 'paltrow', 'and', 'johnathon', 'schaech', 'play', 'helen', 'and', 'jackson', ',', 'a', 'photogenic', 'new', 'york', 'couple', 'on', 'their', 'way', 'to', 'spend', 'christmas', 'vacation', 'at', 'his', 'wealthy', ',', 'well', '-', 'to', '-', 'do', 'family', \"'\", 's', 'horse', 'farm', '/', 'estate', 'kilronan', '.', 'jackson', \"'\", 's', 'mother', 'martha', '(', 'lange', ')', 'runs', 'kilronan', 'all', 'by', 'herself', ',', 'and', 'her', 'genteel', 'southern', 'hospitality', 'makes', 'helen', 'feel', 'welcome', 'immediately', '--', 'even', 'if', 'her', 'first', 'meeting', 'with', 'martha', 'takes', 'place', 'while', 'helen', 'is', 'in', 'the', 'altogether', ',', 'caught', 'red', '-', 'handed', 'after', 'a', 'bedroom', 'romp', 'with', 'her', 'husband', '-', 'to', '-', 'be', '.', 'but', 'it', 'seems', 'that', 'martha', \"'\", 's', 'friendly', 'smile', 'masks', 'a', 'much', 'more', 'threatening', 'demeanor', ';', 'she', \"'\", 's', 'what', 'you', \"'\", 'd', 'call', 'someone', 'who', 'loves', 'too', 'much', '.', 'martha', 'eagerly', ',', 'deviously', 'wants', 'a', 'grandchild', ',', 'and', 'then', 'helen', 'will', 'be', 'expendable', ',', 'as', 'far', 'as', 'she', \"'\", 's', 'concerned', '.', 'if', 'there', \"'\", 's', 'one', 'reason', 'to', 'catch', '\"', 'hush', ',', '\"', 'it', \"'\", 's', 'lange', '.', 'she', 'treats', 'the', 'pedestrian', 'screenplay', 'better', 'than', 'it', 'deserves', 'to', 'be', 'treated', ',', 'injecting', 'martha', '(', 'poorly', 'written', 'though', 'she', 'may', 'be', ')', 'with', 'a', 'little', 'empathy', 'to', 'level', 'out', 'the', 'psycho', '-', 'playing', 'field', '.', 'when', 'she', 'delves', 'into', 'martha', \"'\", 's', 'dark', 'side', ',', 'predictable', 'cliches', '--', 'chain', '-', 'smoking', ',', 'staring', 'in', 'mirrors', ',', 'praying', 'in', 'a', 'confessional', 'to', 'a', 'priest', 'who', 'isn', \"'\", 't', 'there', ',', 'poking', 'a', 'hole', 'in', 'helen', \"'\", 's', 'diaphragm', 'so', 'she', \"'\", 'll', 'become', 'pregnant', '(', 'and', 'she', 'does', ')', '--', 'abound', ',', 'but', 'it', \"'\", 's', 'moderately', 'entertaining', 'junk', 'because', 'lange', 'is', 'such', 'an', 'interesting', 'actress', 'to', 'watch', '.', 'veteran', 'performer', 'nina', 'foch', 'is', 'smart', 'and', 'tart', 'as', 'jackson', \"'\", 's', 'wheelchair', '-', 'bound', 'paternal', 'grandmother', '.', 'the', 'rest', 'of', 'the', 'cast', 'looks', 'ill', 'and', 'uncomfortable', ',', 'especially', 'paltrow', '.', 'but', 'can', 'you', 'really', 'blame', 'them', '?', 'the', 'character', 'relationships', 'in', '\"', 'hush', '\"', 'hold', 'a', 'certain', 'amount', 'of', 'promise', ',', 'at', 'least', 'until', 'their', 'psychological', 'impact', 'is', 'blown', 'out', 'of', 'the', 'water', 'by', 'sheer', 'stupidity', '.', 'idiotic', 'situations', '(', 'martha', 'yells', 'at', 'a', 'nearby', 'horse', 'so', 'it', 'will', 'bolt', 'up', 'and', 'knock', 'helen', 'over', ')', 'compliment', 'idiotic', 'dialogue', '(', '\"', 'why', 'did', 'you', 'yell', '?', '\"', 'helen', 'yells', 'back', 'at', 'martha', ')', ',', 'and', 'the', 'film', 'takes', 'the', 'form', 'of', 'one', 'of', 'the', 'shoddier', 'fill', 'in', 'the', 'blank', '-', 'from', '-', 'hell', 'flicks', 'ever', 'made', '.', 'you', 'can', 'see', 'through', 'a', 'great', 'deal', 'of', 'martha', \"'\", 's', 'actions', 'and', 'lies', 'from', 'their', 'conception', ';', 'why', 'do', 'people', 'who', 'have', 'known', 'this', 'woman', 'for', 'years', 'longer', 'than', 'we', 'have', 'never', 'figure', 'things', 'out', '?', 'does', 'nobody', 'communicate', 'or', 'read', 'the', 'newspaper', 'in', 'this', 'town', '?', 'if', 'any', 'of', 'her', 'potential', 'victims', 'thought', ',', 'acted', 'or', 'behaved', 'like', 'normal', 'people', ',', '\"', 'hush', '\"', 'would', 'be', 'a', 'really', 'short', 'movie', '.', 'and', 'then', 'there', \"'\", 's', 'the', 'climax', 'and', 'ending', ',', 'which', 'abruptly', 'come', 'when', 'helen', 'starts', 'having', 'contractions', 'after', 'eating', 'some', 'pound', 'cake', 'spiked', 'with', 'a', 'labor', '-', 'inducing', 'drug', 'normally', 'used', 'on', 'horses', '.', 'after', 'a', 'really', 'weird', 'chase', 'scene', ',', 'martha', 'calmly', 'knits', 'in', 'a', 'rocking', 'chair', 'while', 'forcing', 'helen', 'to', 'give', 'birth', 'in', 'a', 'bed', 'all', 'by', 'herself', '.', 'i', 'won', \"'\", 't', 'spoil', 'what', 'happens', 'next', 'except', 'to', 'say', 'that', 'it', \"'\", 's', 'contradictory', ',', 'illogical', 'and', '(', 'probably', ',', 'since', 'i', \"'\", 'm', 'no', 'doctor', ')', 'medically', 'impossible', '.', 'the', 'final', 'scene', 'offers', 'no', 'closure', ',', 'no', 'resolution', ',', 'no', 'confrontation', 'whatsoever', '.', 'it', \"'\", 's', 'just', 'there', ',', 'dangling', 'amidst', 'silent', 'displeasure', '.', 'no', 'one', 'should', 'like', 'this', 'ending', ',', 'regardless', 'of', 'their', 'feelings', 'on', 'the', 'preceding', 'material', '.', 'perhaps', '\"', 'hush', '\"', \"'\", 's', 'title', 'is', 'a', 'plea', 'to', 'silence', 'its', 'audience', \"'\", 's', 'likely', 'bitter', 'word', 'of', 'mouth', 'while', 'exiting', 'the', 'theater', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBsANCV51BD8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8a08f6e1-8963-4e9f-f271-1648ab05e421"
      },
      "source": [
        "\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer,LancasterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "stopwords_en = stopwords.words('english')\n",
        "punctuations = \"?:!.,;'\"\n",
        "remove_stopwords = True\n",
        "useStemming = True\n",
        "useLemma = False\n",
        "removePuncs = True\n",
        "for l in range(len(documents)):\n",
        "  label = documents[l][1]\n",
        "  tmpReview = []\n",
        "  for w in documents[l][0]:\n",
        "    newWord = w\n",
        "    if remove_stopwords and (w in stopwords_en):\n",
        "      continue\n",
        "    if removePuncs and (w in punctuations):\n",
        "      continue\n",
        "    if useStemming:\n",
        "      newWord = porter.stem(newWord)\n",
        "    if useLemma:\n",
        "      newWord = wordnet_lemmatizer.lemmatize(newWord)\n",
        "    tmpReview.append(newWord)\n",
        "  documents[l]=(tmpReview,label)\n",
        "print(documents[1])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['call', '\"', 'hush', '\"', '\"', 'stop', 'mom', 'kill', '\"', '\"', 'mommi', 'fearest', '\"', '\"', 'hand', 'rob', 'cradl', '\"', 'call', 'whatev', 'want', 'certainli', 'see', 'unless', 'desper', 'need', 'bad', 'movi', '-', 'induc', 'chuckl', '--', '\"', 'hush', '\"', 'score', 'mani', 'unintent', 'guffaw', 'almost', 'qualifi', 'guilti', 'pleasur', 'chalk', 'loss', 'frequent', 'stupid', 'laps', 'appar', 'post', '-', 'product', 'tinker', '(', 'suppos', 'open', 'year', 'ago', ')', 'latter', 'appear', 'given', '\"', 'hush', '\"', 'send', '-', 'downright', 'infuri', 'bad', '\"', 'hush', '\"', 'laughabl', '-', 'screen', 'talent', '--', 'includ', 'pair', 'gwyneth', 'paltrow', 'jessica', 'lang', '--', 'noth', 'laugh', 'paltrow', 'johnathon', 'schaech', 'play', 'helen', 'jackson', 'photogen', 'new', 'york', 'coupl', 'way', 'spend', 'christma', 'vacat', 'wealthi', 'well', '-', '-', 'famili', 'hors', 'farm', '/', 'estat', 'kilronan', 'jackson', 'mother', 'martha', '(', 'lang', ')', 'run', 'kilronan', 'genteel', 'southern', 'hospit', 'make', 'helen', 'feel', 'welcom', 'immedi', '--', 'even', 'first', 'meet', 'martha', 'take', 'place', 'helen', 'altogeth', 'caught', 'red', '-', 'hand', 'bedroom', 'romp', 'husband', '-', '-', 'seem', 'martha', 'friendli', 'smile', 'mask', 'much', 'threaten', 'demeanor', 'call', 'someon', 'love', 'much', 'martha', 'eagerli', 'devious', 'want', 'grandchild', 'helen', 'expend', 'far', 'concern', 'one', 'reason', 'catch', '\"', 'hush', '\"', 'lang', 'treat', 'pedestrian', 'screenplay', 'better', 'deserv', 'treat', 'inject', 'martha', '(', 'poorli', 'written', 'though', 'may', ')', 'littl', 'empathi', 'level', 'psycho', '-', 'play', 'field', 'delv', 'martha', 'dark', 'side', 'predict', 'clich', '--', 'chain', '-', 'smoke', 'stare', 'mirror', 'pray', 'confession', 'priest', 'poke', 'hole', 'helen', 'diaphragm', 'becom', 'pregnant', '(', ')', '--', 'abound', 'moder', 'entertain', 'junk', 'lang', 'interest', 'actress', 'watch', 'veteran', 'perform', 'nina', 'foch', 'smart', 'tart', 'jackson', 'wheelchair', '-', 'bound', 'patern', 'grandmoth', 'rest', 'cast', 'look', 'ill', 'uncomfort', 'especi', 'paltrow', 'realli', 'blame', 'charact', 'relationship', '\"', 'hush', '\"', 'hold', 'certain', 'amount', 'promis', 'least', 'psycholog', 'impact', 'blown', 'water', 'sheer', 'stupid', 'idiot', 'situat', '(', 'martha', 'yell', 'nearbi', 'hors', 'bolt', 'knock', 'helen', ')', 'compliment', 'idiot', 'dialogu', '(', '\"', 'yell', '\"', 'helen', 'yell', 'back', 'martha', ')', 'film', 'take', 'form', 'one', 'shoddier', 'fill', 'blank', '-', '-', 'hell', 'flick', 'ever', 'made', 'see', 'great', 'deal', 'martha', 'action', 'lie', 'concept', 'peopl', 'known', 'woman', 'year', 'longer', 'never', 'figur', 'thing', 'nobodi', 'commun', 'read', 'newspap', 'town', 'potenti', 'victim', 'thought', 'act', 'behav', 'like', 'normal', 'peopl', '\"', 'hush', '\"', 'would', 'realli', 'short', 'movi', 'climax', 'end', 'abruptli', 'come', 'helen', 'start', 'contract', 'eat', 'pound', 'cake', 'spike', 'labor', '-', 'induc', 'drug', 'normal', 'use', 'hors', 'realli', 'weird', 'chase', 'scene', 'martha', 'calmli', 'knit', 'rock', 'chair', 'forc', 'helen', 'give', 'birth', 'bed', 'spoil', 'happen', 'next', 'except', 'say', 'contradictori', 'illog', '(', 'probabl', 'sinc', 'doctor', ')', 'medic', 'imposs', 'final', 'scene', 'offer', 'closur', 'resolut', 'confront', 'whatsoev', 'dangl', 'amidst', 'silent', 'displeasur', 'one', 'like', 'end', 'regardless', 'feel', 'preced', 'materi', 'perhap', '\"', 'hush', '\"', 'titl', 'plea', 'silenc', 'audienc', 'like', 'bitter', 'word', 'mouth', 'exit', 'theater'], 'neg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0c7MzOF6YO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_features(document):\n",
        "  words = set(document)\n",
        "  features = {}\n",
        "  for w in word_features:\n",
        "    if (w in words):\n",
        "      features[w] = True\n",
        "    else:\n",
        "      features[w] = False\n",
        "  return features\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yiGAd1c21Ph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0d2c852e-c659-4ca3-d69d-3dde258c05ab"
      },
      "source": [
        "all_words = []\n",
        "for w in movie_reviews.words():\n",
        "  if removePuncs and (w in punctuations):\n",
        "    continue\n",
        "  if remove_stopwords and (w in stopwords_en):\n",
        "    continue\n",
        "  all_words.append(w.lower())\n",
        "\n",
        "all_words = nltk.FreqDist(all_words)\n",
        "print(all_words.most_common(15))\n",
        "#use top 3000- 5000 top words\n",
        "word_features = list(all_words.keys())[:5000]\n",
        "featuresets = [(find_features(rev),category) for (rev,category) in documents]\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('\"', 17612), ('-', 15595), (')', 11781), ('(', 11664), ('film', 9517), ('one', 5852), ('movie', 5771), ('like', 3690), ('even', 2565), ('good', 2411), ('time', 2411), ('story', 2169), ('would', 2109), ('much', 2049), ('character', 2020)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJYQ7aAq5om8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "24a3c1b2-d1c2-4ad4-c923-6f7d019f9476"
      },
      "source": [
        "#training\n",
        "training_set = featuresets[:1800]\n",
        "testing_set = featuresets[1800:]\n",
        "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
        "print(\"classifier accuracy percent\",(nltk.classify.accuracy(classifier, testing_set))*100)\n",
        "classifier.show_most_informative_features(15)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier accuracy percent 79.5\n",
            "Most Informative Features\n",
            "                  annual = True              pos : neg    =      9.0 : 1.0\n",
            "                 nervous = True              pos : neg    =      6.3 : 1.0\n",
            "                   rabid = True              neg : pos    =      6.3 : 1.0\n",
            "                   jumbo = True              neg : pos    =      6.3 : 1.0\n",
            "                  stroll = True              neg : pos    =      6.3 : 1.0\n",
            "                   inept = True              neg : pos    =      6.2 : 1.0\n",
            "                    yawn = True              neg : pos    =      6.2 : 1.0\n",
            "                poignant = True              pos : neg    =      6.1 : 1.0\n",
            "                   anger = True              pos : neg    =      5.8 : 1.0\n",
            "                romantic = True              pos : neg    =      5.7 : 1.0\n",
            "                 bronson = True              neg : pos    =      5.7 : 1.0\n",
            "                   dreck = True              neg : pos    =      5.7 : 1.0\n",
            "                  justin = True              neg : pos    =      5.4 : 1.0\n",
            "                abstract = True              pos : neg    =      5.0 : 1.0\n",
            "                  alicia = True              neg : pos    =      5.0 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QLPHbXj8U2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}